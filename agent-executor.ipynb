{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c53d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm= init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e66b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb6b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097e53f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94361248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c782b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbd3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fb6ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ec165b1b-8e76-4830-9215-4c8201c5c23a-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': '394909a2-f043-4311-b7ef-56bfa62bb2bf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 5, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd8978d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 10.0, 'x': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61c91e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'subtract': <function __main__.subtract(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'exponentiate': <function __main__.exponentiate(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "name2tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc9e412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c805c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3e2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54219a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ce07c526-b0c1-4c41-86f4-4a4a53643c17-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': 'f4f902ee-84bc-400a-b1ea-3b07f8e357be', 'type': 'tool_call'}], usage_metadata={'input_tokens': 161, 'output_tokens': 5, 'total_tokens': 166, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ccc2f",
   "metadata": {},
   "source": [
    "Despite having the answer in our `agent_scratchpad`, the LLM still tries to use the tool\n",
    "_again_. This behaviour happens because we bonded the tools to the LLM with\n",
    "`tool_choice=\"any\"`. When we set `tool_choice` to `\"any\"` or `\"required\"`, we tell the\n",
    "LLM that it _MUST_ use a tool, i.e., it cannot provide a final answer.\n",
    "\n",
    "There's two options to fix this:\n",
    "\n",
    "1. Set `tool_choice=\"auto\"` to tell the LLM that it can choose to use a tool or provide\n",
    "a final answer.\n",
    "\n",
    "2. Create a `final_answer` tool - we'll explain this shortly.\n",
    "\n",
    "First, let's try option **1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c3b20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bfdfa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--2be30792-292d-40da-aa11-86d84d8f5b35-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': 'ac82218b-b2c1-4cef-82f9-f175d6cdc704', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 5, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1845455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc5391cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 + 10 is 20.0', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9b8a2213-57ba-49f5-8c73-4ff88a5ac9dc-0', usage_metadata={'input_tokens': 161, 'output_tokens': 13, 'total_tokens': 174, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfea76",
   "metadata": {},
   "source": [
    "We now have the final answer in the `content` field! This method is perfectly\n",
    "functional; however, we recommend option **2** as it provides more control over the\n",
    "agent's output.\n",
    "\n",
    "There are several reasons that option **2** can provide more control, those are:\n",
    "\n",
    "* It removes the possibility of an agent using the direct `content` field when it is not\n",
    "appropriate; for example, some LLMs (particularly smaller ones) may try to use the\n",
    "`content` field when using a tool.\n",
    "\n",
    "* We can enforce a specific structured output in our answers. Structured outputs are\n",
    "handy when we require particular fields for downstream code or multi-part answers. For\n",
    "example, a RAG agent may return a natural language answer and a list of sources used to\n",
    "generate that answer.\n",
    "\n",
    "To implement option **2**, we must create a `final_answer` tool. We will add a\n",
    "`tools_used` field to give our output some structureâ€”in a real-world use case, we\n",
    "probably wouldn't want to generate this field, but it's useful for our example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04f6dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0479f",
   "metadata": {},
   "source": [
    "Our `final_answer` tool _doesn't_ necessarily need to do anything; in this example,\n",
    "we're using it purely to structure our final response. We can now add this tool to our\n",
    "agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6212867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af5efe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to update our name2tool mapping too\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a37707f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d03ba54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'y': 10.0, 'x': 10.0},\n",
       "  'id': '0b49308f-6a22-4952-ad87-4c6bb5ddbcd3',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc081693",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d19c547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3325a92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'final_answer', 'arguments': '{\"tools_used\": [\"add\"], \"answer\": \"The answer is 20.0\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5d96c0e3-5b54-46ac-917b-44541c2ce90a-0', tool_calls=[{'name': 'final_answer', 'args': {'tools_used': ['add'], 'answer': 'The answer is 20.0'}, 'id': '2e09754f-603b-443d-a4b5-ba9b42fc4d32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 231, 'output_tokens': 16, 'total_tokens': 247, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
