{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c838fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import re\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e8eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('http://en.wikipedia.org/wiki/Kevin_Bacon') \n",
    "bs = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35949bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in bs.find('div',{'id':'bodyContent'}).find_all('a',href=re.compile('^(/wiki/)((?!:).)*$')):\n",
    "    if 'href' in link.attrs:\n",
    "        if link.attrs['href']:\n",
    "            print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4c3cb",
   "metadata": {},
   "source": [
    "### writing a recursive function for this,stops when there's no link or user's command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8e42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(int(datetime.datetime.now().timestamp()))\n",
    "def getLinks(url: str):\n",
    "    html = urlopen('http://en.wikipedia.org{}'.format(url))\n",
    "    bs = BeautifulSoup(html,'html.parser')\n",
    "    return bs.find('div',{'id':'bodyContent'}).find_all('a',{'href':re.compile('^(/wiki/)((?!:).)*$')})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e70b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = getLinks('/wiki/Kevin_Bacon') \n",
    "while len(links) > 0: \n",
    "    newArticle = links[random.randint(0, len(links)-1)].attrs['href'] \n",
    "    print(newArticle) \n",
    "    links = getLinks(newArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be40e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = set()\n",
    "def getLinks(url:str):\n",
    "    try:\n",
    "        html = urlopen('http://en.wikipedia.org{}'.format(url))\n",
    "        bs = BeautifulSoup(html,'html.parser')\n",
    "        for link in bs.find_all('a',{'href':re.compile('^(/wiki/)')}):\n",
    "            if 'href' in link.attrs: \n",
    "                if link.attrs['href'] not in pages:\n",
    "                    newPage = link.attrs['href']\n",
    "                    print(newPage)\n",
    "                    pages.add(newPage)\n",
    "                    getLinks(newPage)\n",
    "    except HTTPError as e:\n",
    "        print('{} page not found'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "getLinks('/wiki/Kevin_Bacon')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
